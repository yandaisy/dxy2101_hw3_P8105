dxy2101_hw3_p8105
================
Daisy Yan
10/15/2022

``` r
library(tidyverse)
library(ggplot2)
```

## Problem 2

**Part 1: Load, tidy, and wrangle data.**

``` r
accel_data = 
  read_csv('./data/accel_data.csv') %>%
  janitor::clean_names() %>%
  pivot_longer(
    activity_1:activity_1440,
    names_to = "minute",
    names_prefix = "activity_",
    values_to = "counts"
  ) %>%
  mutate(
    day_type = ifelse(day == c("Saturday", "Sunday"), "weekend", "weekday"),
    minute = as.numeric(minute)
  ) %>%
  relocate(day_type, .before = minute)
```

There are 50400 observations and 6 variables. The variables in this
dataset are the following:

- `week` - week number of accelerometer data collection
- `day_id` - day number of accelerometer data collection
- `day` - day of the week
- `day_type` - weekend vs. weekday
- `minute` - minute of the day
- `counts` - activity counts of the corresponding minute of the day

**Part 2: Aggregate across minutes to create a total activity variable
for each day.**

``` r
accel_data_total =
  accel_data %>%
  group_by(day_id) %>%
  summarise(total_counts = sum(counts))

# view table
accel_data_total_tbl =
  accel_data_total %>%
  knitr::kable(digits = 1)

accel_data_total_tbl
```

| day_id | total_counts |
|-------:|-------------:|
|      1 |     480542.6 |
|      2 |      78828.1 |
|      3 |     376254.0 |
|      4 |     631105.0 |
|      5 |     355923.6 |
|      6 |     307094.2 |
|      7 |     340115.0 |
|      8 |     568839.0 |
|      9 |     295431.0 |
|     10 |     607175.0 |
|     11 |     422018.0 |
|     12 |     474048.0 |
|     13 |     423245.0 |
|     14 |     440962.0 |
|     15 |     467420.0 |
|     16 |     685910.0 |
|     17 |     382928.0 |
|     18 |     467052.0 |
|     19 |     371230.0 |
|     20 |     381507.0 |
|     21 |     468869.0 |
|     22 |     154049.0 |
|     23 |     409450.0 |
|     24 |       1440.0 |
|     25 |     260617.0 |
|     26 |     340291.0 |
|     27 |     319568.0 |
|     28 |     434460.0 |
|     29 |     620860.0 |
|     30 |     389080.0 |
|     31 |       1440.0 |
|     32 |     138421.0 |
|     33 |     549658.0 |
|     34 |     367824.0 |
|     35 |     445366.0 |

By only looking at the table, there does not seem to be an apparent
trend.

``` r
accel_data_total %>%
  ggplot(aes(x = day_id, y = total_counts)) +
  geom_point() + geom_line()
```

![](dxy2101_hw3_p8105_files/figure-gfm/total_counts%20plot-1.png)<!-- -->

Plotting the total daily activity counts by day also showcases no
apparent trend. However, there are noticeable dips in activity on 2, 24,
and 31.

**Part 3: Plot the 24-hour activity time courses for each day.**

``` r
accel_data %>%
  mutate(day = forcats::fct_relevel(day, c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"))
         ) %>%
  ggplot(aes(x = minute, y = counts, color = day)) +
  geom_point(alpha = 0.5) +
  labs(
    title = "24 Hour Activity Time Course",
    x = "Minute of the Day",
    y = "Activity Count"
    ) +
  scale_x_continuous(
    breaks = c(1, 720, 1440)
  )
```

![](dxy2101_hw3_p8105_files/figure-gfm/24hr%20plot-1.png)<!-- -->

According to the 24 Hour Activity Time Course plot, it appears that
there are generally spikes in activity during the mid-morning, the
afternoon, and in the late evening. Activity is especially low during
towards the end of the night and early morning, presumably because the
individual is asleep during those hours. Afternoon spike in activity is
especially apparent on Sundays while the late evening spike in activity
is especially apparent on Mondays, Wednesdays, Fridays, and Saturdays.
Saturdays also showcase a spike in activity in the late afternoon.

## Problem 3

**Part 1: Data Cleaning.**

``` r
library(p8105.datasets)
data("ny_noaa")
```

``` r
ny_noaa_clean =
  ny_noaa %>%
  janitor::clean_names() %>%
  separate(col = date, into = c("year", "month", "day"), sep = "-") %>%
  mutate(month = recode(month, "01" = "jan", "02" = "feb",
                "03" = "mar", "04" = "apr", "05" = "may",
                "06" = "jun", "07" = "jul", "08" = "aug",
                "09" = "sep", "10" = "oct", "11" = "nov",
                "12" = "dec")) %>%
  mutate(
    prcp = as.numeric(prcp),
    snow = as.numeric(snow),
    snwd = as.numeric(snwd),
    tmax = as.numeric(tmax),
    tmin = as.numeric(tmin)
  ) %>%
  # ensure observations for tmax, tmin, and prcp are in reasonable units
  mutate(
    prcp = prcp / 10,
    tmax = tmax / 10,
    tmin = tmin / 10
  )
```

There are 2595176 observations and 9 variables. The variables in this
dataset that will be used in the following plots are :

- `id` - station id
- `year` - year of observation
- `month` - month of observation
- `snow` - snow fall (mm)
- `tmax` - maximum temperature (degrees C)
- `tmin` - minimum temperature (degrees C)

It is important to note that this dataset has extensive missing data.
This is because each weather station can only collect a subset of
variables. The percentage of missing data for each climate variable is
the following:

- 5.6195803% of precipitation data is missing.
- 14.689601% of snowfall data is missing.
- 43.7102532% of maximum temperature data is missing.
- 43.7126422% of minimum temperature data is missing.

``` r
ny_noaa_clean %>%
  group_by(snow) %>%
  summarize(n_obs = n()) %>%
  arrange(desc(n_obs))
```

    ## # A tibble: 282 × 2
    ##     snow   n_obs
    ##    <dbl>   <int>
    ##  1     0 2008508
    ##  2    NA  381221
    ##  3    25   31022
    ##  4    13   23095
    ##  5    51   18274
    ##  6    76   10173
    ##  7     8    9962
    ##  8     5    9748
    ##  9    38    9197
    ## 10     3    8790
    ## # … with 272 more rows

The most commonly observed value for snowfall is 0 mm. This is because
snowfall only occurs during the winter months in NY, which is only 3
months out of the entire year. Even then, snowfall does not occur
continuously throughout the winter.

**Part 2: Plot the average max temperature in January and in July in
each station across years.**

``` r
ny_noaa_tmax =
  ny_noaa_clean %>%
  drop_na() %>%
  group_by(id) %>%
  mutate(
    avg_tmax = mean(tmax)
    ) 

summer = 
  ny_noaa_tmax %>%
  filter(month %in% c("jun", "jul")) %>%
  mutate(month = recode(month, "jun" = "June", "jul" = "July")) %>%
  mutate(month = forcats::fct_relevel(month, c("June", "July")))
```

``` r
ggplot(data = summer, aes(x = year, y = avg_tmax)) +
  geom_boxplot() + coord_flip() + facet_grid(~month) +
    labs(
    title = "Average Maximum Temperature in June vs. July from 1981-2010",
    x = "Year",
    y = "Average Tmax (°C) by Station"
    )
```

![](dxy2101_hw3_p8105_files/figure-gfm/tmax%20plot-1.png)<!-- -->

The median value for the average maximum temperature is similar between
June and July, falling just below 15 degrees Celsius. Furthermore, both
months exhibit similar and uniform ranges in average maximum temperature
values across 1981 to 2010, with the range slightly decreasing in the
2000a. There are outliers in both months, particularly in the years
1988-1994.

**Part 3: Plot tmax vs tmin for entire dataset and distribution of
snowfall values greater than 0 and less than 100 separately by year.**

``` r
library(patchwork)
```

``` r
tmax_tmin =
  ggplot(data = ny_noaa_clean, aes(x = tmax, y = tmin)) +
  geom_hex() +
  labs(title = "Max vs Min Temperature in NY from 1981-2010", 
       x = "Maximum temperature (°C)", 
       y = "Minimum temperature (°C)") +
  theme(plot.title = element_text(size = 10))

snow = 
  ny_noaa_clean %>%
  filter(snow > 0 & snow < 100) %>%
  ggplot(aes(x = year, y = snow, fill = year)) + 
  geom_violin(alpha = 0.5 ) +
  labs(title = "Distribution of Snowfall between 0-100 mm by Year", 
       x = "Year", 
       y = "Snowfall (mm)") +
  scale_x_discrete(breaks = c(1981, 1990, 2000, 2010)) +
  theme(plot.title = element_text(size = 10),
          legend.key.size = unit(0.05, "cm"), 
          legend.text = element_text(size = 7),
          legend.direction = "horizontal")


gridExtra::grid.arrange(tmax_tmin,  snow, heights = c(0.5,  0.5), nrow = 2 )
```

![](dxy2101_hw3_p8105_files/figure-gfm/temp%20and%20snow%20plot-1.png)<!-- -->

From the hex graph of maximum temperature vs. minimum temperature, we
can see that there is a higher count of both maximum temperature and
minimum temperature as both values increase. This may be useful for
further analysis to assess the correlation between the two variables and
potentially the sensitivity of the weather stations.

From the violin graph of snowfall distribution, we can see that for all
years (1981-2010), the distribution of snowfall is right skewed.
Meaning, there are more observations in which there are lower levels of
snowfall than higher levels of snowfall. This corresponds to Part 1 of
Problem 3, where the most commonly observed value of snowfall is 0 mm.
